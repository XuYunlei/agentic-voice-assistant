# Agentic Voice-to-Voice Product Discovery Assistant

End-to-end demo: voice input â†’ agentic planning with LangGraph â†’ RAG over Amazon 2020 slice via MCP â†’ optional live web comparison â†’ grounded, cited answer â†’ TTS playback.


### **Phase 1 â€” Complete Pipeline**

Voice-to-Voice Â· RAG + Web Hybrid Â· MCP-Powered Agents

---

## ğŸš€ Overview

This project implements an **agentic multimodal product search assistant** using:

* **LangGraph** for multi-step agent orchestration
* **HuggingFace Amazon 2020 dataset** (15 columns â€” no rating, no reviews)
* **ChromaDB** vector index
* **MCP server** exposing RAG + Web Search tools
* **Brave Search API**
* **Whisper ASR** for speech
* **OpenAI TTS** for final spoken answers
* **Streamlit UI** for a voice-to-voice demo

The system takes a userâ€™s voice input â†’ converts to text â†’ interprets intent â†’ fetches products via RAG and/or web search â†’ returns an answer â†’ speaks the answer back.

**Phase 1 is 100% implemented and working.**

---

# ğŸ“ Project Structure

```
agentic-voice-assistant/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ ui_streamlit.py               # Main Streamlit voice UI
â”‚   â”œâ”€â”€ audio_utils.py                # (optional placeholder)
â”‚   â””â”€â”€ components.py                 # (optional placeholder)
â”‚
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ env.example
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed/products.csv        # HF Amazon 2020 dataset (15 cols)
â”‚   â””â”€â”€ index/                        # Chroma DB (auto-created)
â”‚
â”œâ”€â”€ graph/
â”‚   â”œâ”€â”€ langgraph_pipeline.py
â”‚   â”œâ”€â”€ schemas.py
â”‚   â””â”€â”€ nodes/
â”‚       â”œâ”€â”€ router.py
â”‚       â”œâ”€â”€ planner.py
â”‚       â”œâ”€â”€ retriever.py
â”‚       â”œâ”€â”€ answerer.py
â”‚       â””â”€â”€ critic.py
â”‚
â”œâ”€â”€ indexing/
â”‚   â””â”€â”€ build_index.py                # Build HFâ†’Chroma vector index
â”‚
â”œâ”€â”€ mcp_server/
â”‚   â”œâ”€â”€ server.py                     # FastAPI MCP server
â”‚   â””â”€â”€ tools/
â”‚       â”œâ”€â”€ rag_tool.py
â”‚       â””â”€â”€ web_tool.py
â”‚
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ system_router.md
â”‚   â”œâ”€â”€ system_planner.md
â”‚   â”œâ”€â”€ system_answerer.md
â”‚   â””â”€â”€ tool_call_instructions.md     # (empty for Phase 1)
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ build_index.sh
â”‚   â”œâ”€â”€ run_mcp.sh
â”‚   â””â”€â”€ run_ui.sh
â”‚
â””â”€â”€ tts_asr/
    â”œâ”€â”€ asr_whisper.py
    â””â”€â”€ tts_client.py
```

---

# ğŸ”§ Installation & Setup

### 1ï¸âƒ£ Create environment

```bash
conda create -n GenAI python=3.10 -y
conda activate GenAI
pip install -r requirements.txt
```

---

### 2ï¸âƒ£ Add environment variables

Create `.env` using `configs/env.example` as a reference:

```
OPENAI_API_KEY=
BRAVE_API_KEY=
SEARCH_PROVIDER=brave

EMBED_MODEL=all-MiniLM-L6-v2
GEN_MODEL=openai/gpt-4o-mini

ASR_MODEL=small
TTS_PROVIDER=openai
TTS_VOICE=alloy

INDEX_PATH=./data/index
DATA_PRODUCTS=./data/processed/products.csv

MCP_BASE=http://127.0.0.1:8000
```

---

# ğŸ“¦ Phase 1 Components

## 1ï¸âƒ£ HF Dataset â†’ Chroma Index

`indexing/build_index.py`:

* Renames HF fields:
  `Uniq Id â†’ id`, `Product Name â†’ title`, `Selling Price â†’ price`, etc.
* Cleans price (`$` removal â†’ float)
* Extracts `price_per_oz` if possible
* Ensures **all metadata is Chroma-safe**
* Adds docs to collection `amazon2020`

Build index:

```bash
bash scripts/build_index.sh
```

---

## 2ï¸âƒ£ MCP Server (Tools)

Start MCP:

```bash
bash scripts/run_mcp.sh
```

### Tools exposed:

#### `/rag.search`

* Semantic search (SentenceTransformer)
* Optional price filters (`lte` / `gte`)
* Output fields:

  * `doc_id`
  * `title`
  * `price`
  * `brand` (placeholder)
  * `sku`

#### `/web.search`

* Brave Web API
* Returns:

  * `title`
  * `url`
  * `snippet`
  * `profile`

Test:

```bash
curl -X POST http://127.0.0.1:8000/rag.search \
  -H "Content-Type: application/json" \
  -d '{"query":"stainless steel cleaner"}'
```

---

## 3ï¸âƒ£ Agent Workflow (LangGraph)

Workflow:
`router â†’ planner â†’ retriever â†’ answerer â†’ critic`

### router

* Classifies intent
* Decides:

  * RAG only
  * Web only
  * Both
* Extracts filters (brand, price)

### planner

* Ensures filters match HF (price only)
* Decides tool list

### retriever

* Calls MCP endpoints
* Stores RAG/Web evidence

### answerer

* HF dataset contains **NO ratings, ingredients, reviews**
* So answerer uses:

  * `title`
  * `price`
  * `brand` (empty)
* Sorts by **price only**
* Generates citations

### critic

* Placeholder for Phase 2 enhancements

---

## 4ï¸âƒ£ Voice UI (Streamlit)

Run UI:

```bash
bash scripts/run_ui.sh
```

Features:

* Audio recording
* Whisper ASR
* Multi-agent reasoning
* Product results table
* Citations
* OpenAI TTS playback

Open browser:

```
http://localhost:8501
```

---

# ğŸ”¥ Next: Phase 2 Enhancements

Coming next:

* Tool Normalization Layer
* Conflict resolution engine
* Webâ€“RAG merge logic
* Better product ranking
* Metadata extraction from web
* Price-per-oz ranking logic
* Safety + chemical constraints
* Critic rewrite for chain integrity
* LLM fallback for missing data
* Scoring systems for final answers
